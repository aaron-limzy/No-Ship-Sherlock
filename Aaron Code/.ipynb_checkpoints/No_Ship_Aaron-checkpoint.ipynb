{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "import matplotlib\n",
    "import cufflinks as cf\n",
    "import plotly\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "import os\n",
    "#pip install chart_studio\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "#pd.options.plotting.backend = \"plotly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full path of where all the raw data is stored.\n",
    "full_path = r\"D:\\Google Drive\\Masters\\Sem 3\\EBAC No Ship, Sherlock\\Capstone\\raw data\"\n",
    "\n",
    "# Where all the monthly data are stored.\n",
    "monthly_folder_name = full_path + \"\\\\monthly\"\n",
    "\n",
    "# Want to get the shipment data. Need the shipment excel name.\n",
    "excel_route_file = \"APJ Route TAT Master File V20210129.xlsx\"\n",
    "\n",
    "\n",
    "\n",
    "# Must be in the same directory as Juypter notebook\n",
    "from Shared_Lib import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Masterdata of shipment routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Excel: 11958\n",
      "The count of mode by air: 0\n"
     ]
    }
   ],
   "source": [
    "# Want to get the shipment data\n",
    "# Using the Shared Lib\n",
    "df_ship_routes = get_shipment_routes(full_path + \"\\\\\" + excel_route_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11958"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_ship_routes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual Shipment Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_names = [f for f in os.listdir(monthly_folder_name) if f.find(\"SearchResult\")>=0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To read all the excel sheets. \n",
    "df_unique_shipment_all = pd.DataFrame()\n",
    "for f in file_names:\n",
    "    df_unique_shipment_all=df_unique_shipment_all.append(get_shipment_data(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaniness/exploratory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique_shipment = df_unique_shipment_all.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique_shipment_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we want to drop the duplicates. \n",
    "#df_unique_shipment.drop_duplicates(keep=\"first\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"There are a total of : {len(df_unique_shipment):,} data\")\n",
    "print(f\"There are {len(df_unique_shipment['Shipment id'].unique()):,} unique shipment Ids\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast to datetime. \n",
    "def column_to_datetime(df):\n",
    "    col_to_datetime = ['Departed from Origin Port Milestone Local Time',\n",
    "       'Departed from Origin Port Milestone Time',\n",
    "       'Departed from Origin Port Milestone Received Time',\n",
    "       'Arrived at Destination Port Milestone Local Time',\n",
    "       'Arrived at Destination Port Milestone Time',\n",
    "       'Arrived at Destination Port Milestone Received Time',\n",
    "       'Est. Arrival at Destination Port Milestone Local Time',\n",
    "       'Est. Arrival at Destination Port Milestone Time',\n",
    "       'Est. Arrival at Destination Port Milestone Received Time']\n",
    "\n",
    "    for col in col_to_datetime:\n",
    "        #df = df[df[c].notnull()] # Want to get rid of all the null values. \n",
    "\n",
    "        print(\"Changing Column '{}' to datetime.\".format(col))\n",
    "        df[col] = pd.to_datetime(df[col], format='%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique_shipment = column_to_datetime(df_unique_shipment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What the timeline should look like. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats_recieved_vs_actual(df, milestone_recieved, milestone_time):\n",
    "\n",
    "    milestone_recieved_year = pd.DatetimeIndex(df[milestone_recieved]).year\n",
    "    milestone_recieved_month = pd.DatetimeIndex(df[milestone_recieved]).month\n",
    "\n",
    "    print(f\"Recieved Year: {list(milestone_recieved_year.unique())}\")\n",
    "    print(f\"Recieved Month : {list(milestone_recieved_month.unique())}\")\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(f\"The summary of '{milestone_recieved}' - '{milestone_time}'\")\n",
    "    timediff = (df[milestone_recieved] -df[milestone_time]).dt.days\n",
    "    print(timediff[timediff.notna()].describe().apply(lambda x: format(x, ',.2f')))\n",
    "    \n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "milestone_recieved = \"Departed from Origin Port Milestone Received Time\"\n",
    "milestone_time = 'Departed from Origin Port Milestone Time'\n",
    "\n",
    "get_stats_recieved_vs_actual(df_unique_shipment, milestone_recieved, milestone_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the Max is 366. We will assume that's an error of 1 year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will be used to correct all the recieved/actual time that has year issues. \n",
    "def correct_milestone_actual_timediff(df_original, milestone_recieved, milestone_time, check_days, correction_days):\n",
    "    df = df_original.copy()\n",
    "    df[milestone_time]=df[milestone_time].mask((df[milestone_recieved] -  df[milestone_time]).dt.days > check_days, \\\n",
    "                                                        df[milestone_time] +  pd.to_timedelta(correction_days, unit='D'))\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Will be used to correct all the recieved/actual time that has year issues. \n",
    "# This function are for those that are negative. \n",
    "def correct_negative_milestone_actual_timediff(df_original, milestone_recieved, milestone_time, check_days, correction_days):\n",
    "    df = df_original.copy()\n",
    "    df[milestone_time]=df[milestone_time].mask((df[milestone_recieved] -  df[milestone_time]).dt.days < check_days, \\\n",
    "                                                        df[milestone_time] -  pd.to_timedelta(correction_days, unit='D'))\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that we did the 1 year correction for the Departure timings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "milestone_recieved = \"Departed from Origin Port Milestone Received Time\"\n",
    "milestone_time = 'Departed from Origin Port Milestone Time'\n",
    "\n",
    "get_stats_recieved_vs_actual(correct_milestone_actual_timediff(\n",
    "    df_unique_shipment, milestone_recieved, milestone_time, 300, 366), \n",
    "                             milestone_recieved, milestone_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Arrival Timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "milestone_recieved = \"Arrived at Destination Port Milestone Received Time\"\n",
    "milestone_time = 'Arrived at Destination Port Milestone Time'\n",
    "\n",
    "get_stats_recieved_vs_actual(df_unique_shipment, milestone_recieved, milestone_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "milestone_recieved = \"Arrived at Destination Port Milestone Received Time\"\n",
    "milestone_time = 'Arrived at Destination Port Milestone Time'\n",
    "\n",
    "df_arr = correct_milestone_actual_timediff(\n",
    "    df_unique_shipment, milestone_recieved, milestone_time, 300, 366)\n",
    "get_stats_recieved_vs_actual(df_arr, milestone_recieved, milestone_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arr[(df_arr[milestone_recieved] - df_arr[milestone_time]).dt.days > 120] \\\n",
    "    [[\"Shipment id\", milestone_recieved, milestone_time, \"Departed from Origin Port Milestone Received Time\", \"Shipment date\", \"Delivered date\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Estimated Timings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "milestone_recieved = \"Est. Arrival at Destination Port Milestone Received Time\"\n",
    "milestone_time = 'Est. Arrival at Destination Port Milestone Time'\n",
    "\n",
    "get_stats_recieved_vs_actual(df_unique_shipment, milestone_recieved, milestone_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we have some that are -733 days. Let's have a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique_shipment[(df_unique_shipment[milestone_recieved] - df_unique_shipment[milestone_time]).dt.days < -700]\\\n",
    "[['Shipment id', milestone_recieved, milestone_time]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like they keyed in the wrong year. Let's correct that by taking away 2 years, to make it 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_correct_est = correct_negative_milestone_actual_timediff(df_unique_shipment, milestone_recieved, milestone_time, -700, 731)\n",
    "\n",
    "get_stats_recieved_vs_actual(df_correct_est, milestone_recieved, milestone_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are still -378 and 366. Meaning, we have to correct positively by 1 year, and negatively by 1 year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_correct_est = correct_negative_milestone_actual_timediff(df_correct_est, milestone_recieved, milestone_time, -300, 366)\n",
    "\n",
    "get_stats_recieved_vs_actual(df_correct_est, milestone_recieved, milestone_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_correct_est = correct_milestone_actual_timediff(df_correct_est, milestone_recieved, milestone_time, 300, 366)\n",
    "\n",
    "get_stats_recieved_vs_actual(df_correct_est, milestone_recieved, milestone_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_correct_est = correct_negative_milestone_actual_timediff(df_correct_est, milestone_recieved, milestone_time, -150, 150)\n",
    "get_stats_recieved_vs_actual(df_correct_est, milestone_recieved, milestone_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_correct_est[(df_correct_est[milestone_recieved]-df_correct_est[milestone_time]).dt.days > 100][[milestone_recieved, milestone_time]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Takes a df and 2 of it's columns. If the original is null, replaces it with the replacement. \n",
    "# def replace_original_if_null(df, original, replacement):\n",
    "#     df[original] = df.apply(\n",
    "#         lambda row: row[replacement] if pd.isnull(row[original]) else row[original],\n",
    "#         axis=1)\n",
    "#     return df\n",
    "\n",
    "def wrongyear_data_cleaning(df):\n",
    "        # ---------------- Correction of timing for 2020/2021/2022 -------------------------\n",
    "    \n",
    "    \n",
    "    # Correct Departed where it's 1 year off. \n",
    "    milestone_recieved = \"Departed from Origin Port Milestone Received Time\"\n",
    "    milestone_time = 'Departed from Origin Port Milestone Time'\n",
    "    df = correct_milestone_actual_timediff(df, milestone_recieved, milestone_time, 300, 366)\n",
    "\n",
    "\n",
    "    # Correct Arrived where it's 1 year off. \n",
    "    milestone_recieved = \"Arrived at Destination Port Milestone Received Time\"\n",
    "    milestone_time = 'Arrived at Destination Port Milestone Time'\n",
    "    df = correct_milestone_actual_timediff(df, milestone_recieved, milestone_time, 300, 366)\n",
    "\n",
    "    # Correct Estimated where it's 1 year off. \n",
    "    milestone_recieved = \"Est. Arrival at Destination Port Milestone Received Time\"\n",
    "    milestone_time = 'Est. Arrival at Destination Port Milestone Time'\n",
    "\n",
    "\n",
    "    # Correct Estimated where it's -1 and -2 year off. \n",
    "    df = correct_negative_milestone_actual_timediff(df, milestone_recieved, milestone_time, -700, 731)\n",
    "    df = correct_negative_milestone_actual_timediff(df, milestone_recieved, milestone_time, -300, 366)\n",
    "    \n",
    "    #df = correct_negative_milestone_actual_timediff(df, milestone_recieved, milestone_time, -150, 150)\n",
    "    # 1) Correct by ID Based on Eyeball. BL = 580041033000\n",
    "    # 2) Don't do it. \n",
    "    \n",
    "    df = correct_milestone_actual_timediff(df, milestone_recieved, milestone_time, 300, 366)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "#     #Change Arrived at destination port year from 2020 to 2021 when ATA time - ATA received time < -300 \n",
    "#     df['Arrived at Destination Port Milestone Time'] = df['Arrived at Destination Port Milestone Time'].mask(\n",
    "#         (df['Arrived at Destination Port Milestone Received Time'] - \\\n",
    "#          df['Arrived at Destination Port Milestone Time']).dt.days > 300, \n",
    "#         df['Arrived at Destination Port Milestone Time'] +  pd.to_timedelta(366, unit='D'))\n",
    "    \n",
    "    \n",
    "# #     df['Arrived at Destination Port Milestone Local Time'] = df['Arrived at Destination Port Milestone Local Time'].mask(\n",
    "# #         (df['Arrived at Destination Port Milestone Local Time'] - \\\n",
    "# #              df['Arrived at Destination Port Milestone Time']).dt.days < -300,\n",
    "# #             df['Arrived at Destination Port Milestone Local Time'] +  pd.to_timedelta(366, unit='D'))\n",
    "    \n",
    "#     #Change Arrived at destination port year from 2022 to 2021 when ATA time - ATA received time > 300 \n",
    "#     df['Arrived at Destination Port Milestone Time'] = df['Arrived at Destination Port Milestone Time'].mask(\n",
    "#         (df['Arrived at Destination Port Milestone Time']- \\\n",
    "#                          df['Arrived at Destination Port Milestone Received Time']).dt.days >= 300, \n",
    "#         df['Arrived at Destination Port Milestone Time'] -  pd.to_timedelta(366, unit='D'))\n",
    "    \n",
    "    \n",
    "# #     df['Arrived at Destination Port Milestone Local Time'] = df['Arrived at Destination Port Milestone Local Time'].mask(\n",
    "# #         (df['Arrived at Destination Port Milestone Local Time'] - \\\n",
    "# #          df['Arrived at Destination Port Milestone Time']).dt.days > 300, \n",
    "# #         df['Arrived at Destination Port Milestone Local Time'] -  pd.to_timedelta(366, unit='D'))\n",
    "\n",
    "\n",
    "\n",
    "#     #Change Departed from Origin Port Milestone year from 2020 to 2021 when ATD time - ATD received time < -300 \n",
    "#     df['Departed from Origin Port Milestone Time'] = df['Departed from Origin Port Milestone Time'].mask(\n",
    "#         (df['Departed from Origin Port Milestone Received Time'] - \\\n",
    "#          df['Departed from Origin Port Milestone Time']).dt.days < -300, \n",
    "#         df['Departed from Origin Port Milestone Time'] +  pd.to_timedelta(366, unit='D'))\n",
    "    \n",
    "# #     df['Departed from Origin Port Milestone Local Time'] = df['Departed from Origin Port Milestone Local Time'].mask(\n",
    "# #         (df['Departed from Origin Port Milestone Local Time'] - \\\n",
    "# #          df['Departed from Origin Port Milestone Time']).dt.days < -300, \n",
    "# #         df['Departed from Origin Port Milestone Local Time'] +  pd.to_timedelta(366, unit='D'))\n",
    "    \n",
    "    \n",
    "    \n",
    "#     # Change the Estimated arrival if it's more than 1 year apart. \n",
    "#     df['Est. Arrival at Destination Port Milestone Time'] = df['Est. Arrival at Destination Port Milestone Time'].mask(\n",
    "#         (df['Arrived at Destination Port Milestone Time'] - \\\n",
    "#          df['Est. Arrival at Destination Port Milestone Time']).dt.days < -300, \n",
    "#         df['Est. Arrival at Destination Port Milestone Time'] -  pd.to_timedelta(366, unit='D'))\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def data_cleaning(df):\n",
    "    \n",
    "    df = df[~df.duplicated()]\n",
    "    \n",
    "    # First, Want to clean up data that is obviously duplicated. \n",
    "    print(\"Data that is duplicated exactly: {}\".format(sum(df.duplicated())))\n",
    "    \n",
    "    print(\"Shape after dedup: {}\".format(df.shape))\n",
    "\n",
    "    # If H-K missing, replace with Latest D-G\n",
    "    #[(Replacement, original)]\n",
    "    replace_column = [('Onboard at Origin Port Milestone Local Time','Departed from Origin Port Milestone Local Time'),\n",
    "       ('Onboard at Origin Port Milestone Time','Departed from Origin Port Milestone Time'),\n",
    "       ('Onboard at Origin Port Milestone Received Time','Departed from Origin Port Milestone Received Time'),\n",
    "       ('Onboard at Origin Port Milestone Source', 'Departed from Origin Port Milestone Source')]\n",
    "    \n",
    "    for (r,o) in replace_column:\n",
    "        df[o] = df[o].mask(df[o].isna(), df[r])\n",
    "        #df =  replace_original_if_null(df=df, original=o, replacement=r)\n",
    "        \n",
    "    print(\"Shape after replacement: {}\".format(df.shape))\n",
    "        \n",
    "    \n",
    "    # Cast to datetime. \n",
    "#     col_to_datetime = ['Departed from Origin Port Milestone Local Time',\n",
    "#        'Departed from Origin Port Milestone Time',\n",
    "#        'Departed from Origin Port Milestone Received Time',\n",
    "#        'Arrived at Destination Port Milestone Local Time',\n",
    "#        'Arrived at Destination Port Milestone Time',\n",
    "#        'Arrived at Destination Port Milestone Received Time',\n",
    "#        'Est. Arrival at Destination Port Milestone Local Time',\n",
    "#        'Est. Arrival at Destination Port Milestone Time',\n",
    "#        'Est. Arrival at Destination Port Milestone Received Time']\n",
    "\n",
    "#     for col in col_to_datetime:\n",
    "#         #df = df[df[c].notnull()] # Want to get rid of all the null values. \n",
    "        \n",
    "#         print(\"Changing Column '{}' to datetime.\".format(col))\n",
    "#         df[col] = pd.to_datetime(df[col], format='%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "#         #df[c] = df[c].apply(lambda x: datetime.datetime.strptime(x,'%Y-%m-%d %H:%M:%S') if not pd.isnull(x) else x)\n",
    "    \n",
    "    # Changed the needed columns to datetime. \n",
    "    df = column_to_datetime(df)\n",
    "    print(\"Shape after col_to_datetime: {}\".format(df.shape))\n",
    "\n",
    "\n",
    "    # Want to do the year clean up for those data with wrongly labelled years. \n",
    "    df = wrongyear_data_cleaning(df)\n",
    "    \n",
    "    print(\"Shape after wrongyear_data_cleaning: {}\".format(df.shape))\n",
    "        \n",
    "    #Remove entries where Arrival Milestone Received Time is earlier than Departure Time\n",
    "    df = df[df[\"Departed from Origin Port Milestone Time\"] < df[\"Arrived at Destination Port Milestone Received Time\"]]\n",
    "    print(\"Shape after 1: {}\".format(df.shape))\n",
    "\n",
    "    #Remove entries where Arrival is earlier than Departure.\n",
    "    df = df[df[\"Departed from Origin Port Milestone Time\"] < df[\"Arrived at Destination Port Milestone Time\"]]\n",
    "    print(\"Shape after 2: {}\".format(df.shape))\n",
    "\n",
    "    #\"Est. Arrival at Destination Port Milestone Received Time\" < \"Arrived at Destination Port Milestone Time\"\n",
    "    df = df[df[\"Est. Arrival at Destination Port Milestone Received Time\"] < df[\"Arrived at Destination Port Milestone Time\"]]\n",
    "    print(\"Shape after 3: {}\".format(df.shape))\n",
    "    \n",
    "    #\"Est. Arrival at Destination Port Milestone Received Time\" < \"Arrived at Destination Port Milestone Received Time\"\n",
    "    df=df[df[\"Est. Arrival at Destination Port Milestone Received Time\"] < df[\"Arrived at Destination Port Milestone Received Time\"]]\n",
    "    print(\"Shape after 4: {}\".format(df.shape))\n",
    "    \n",
    "    \n",
    "    ## R Later than I\n",
    "     #Remove entries where Est. Arrival at Destination Port Milestone Received Time is later than Arrived at Destination Port Milestone Time.\n",
    "     #\"Est. Arrival at Destination Port Milestone Received Time\" > \"Departed from Origin Port Milestone Time\"\n",
    "    df=df[df[\"Departed from Origin Port Milestone Time\"] < df[\"Est. Arrival at Destination Port Milestone Time\"]]\n",
    "    print(\"Shape after 5: {}\".format(df.shape))\n",
    "\n",
    "     # Sort by Latest M, Take earliest R\n",
    "     # \"Arrived at Destination Port Milestone Time\"\n",
    "     # \"Est. Arrival at Destination Port Milestone Received Time\"\n",
    "    df.sort_values([\"Arrived at Destination Port Milestone Time\", \"Est. Arrival at Destination Port Milestone Received Time\"], \\\n",
    "                   ascending=[False, True], inplace=True)\n",
    "    \n",
    "    print(\"Shape after 6: {}\".format(df.shape))\n",
    "\n",
    "    #df = df[~df.duplicated()]\n",
    "    \n",
    "    # Drop the duplicated Shipment IDs.\n",
    "    # Want the First ones, since we have sorted it already\n",
    "    df.drop_duplicates(subset=['Shipment id'], keep='first', inplace=True)\n",
    "    print(\"Shape after 7: {}\".format(df.shape))\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_unique_shipment[(df_unique_shipment['Departed_Origin_Recieved_Year'] == 2020) & (df_unique_shipment['Departed_Origin_Recieved_Month'] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique_shipment_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique_shipment_all[\"Shipment id\"].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_check = df_unique_shipment_all.copy()\n",
    "# df_check.drop_duplicates(keep=\"first\", inplace=True)\n",
    "# df_check = column_to_datetime(df_check)\n",
    "#df_check = wrongyear_data_cleaning(df_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct Estimated where it's 1 year off. \n",
    "# milestone_recieved = \"Est. Arrival at Destination Port Milestone Received Time\"\n",
    "# milestone_time = 'Est. Arrival at Destination Port Milestone Time'\n",
    "# get_stats_recieved_vs_actual(df_check, milestone_recieved, milestone_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct Estimated where it's 1 year off. \n",
    "# milestone_recieved = \"Est. Arrival at Destination Port Milestone Received Time\"\n",
    "# milestone_time = 'Est. Arrival at Destination Port Milestone Time'\n",
    "\n",
    "\n",
    "# # Correct Estimated where it's -1 and -2 year off. \n",
    "\n",
    "# df_check = correct_negative_milestone_actual_timediff(df_check, milestone_recieved, milestone_time, -700, 732)\n",
    "# df_check = correct_negative_milestone_actual_timediff(df_check, milestone_recieved, milestone_time, -300, 366)\n",
    "# get_stats_recieved_vs_actual(df_check, milestone_recieved, milestone_time)\n",
    "#df = correct_milestone_actual_timediff(df, milestone_recieved, milestone_time, 300, 366)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique_shipment_original = data_cleaning(df_unique_shipment_all.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique_shipment = df_unique_shipment_original.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique_shipment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_unique_shipment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_unique_shipment[\"Shipment id\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column to check the difference between the estimated, and the actual arrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique_shipment[\"Delay Est/Arrival Duration\"] = df_unique_shipment[\"Arrived at Destination Port Milestone Time\"] - df_unique_shipment[\"Est. Arrival at Destination Port Milestone Time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique_shipment[\"Delay Est/Arrival Duration\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Want to do a little clean up here as there are ships that are earlier by 100 days\n",
    "df_unique_shipment[df_unique_shipment[\"Delay Est/Arrival Duration\"] < pd.Timedelta('-360 days')]\\\n",
    "[['Shipment id', \"Delay Est/Arrival Duration\", \"Arrived at Destination Port Milestone Time\", \\\n",
    "  \"Est. Arrival at Destination Port Milestone Time\", 'Est. Arrival at Destination Port Milestone Received Time' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique_shipment[df_unique_shipment[\"Delay Est/Arrival Duration\"]<pd.Timedelta(\"0 days\")].sort_values(\"Delay Est/Arrival Duration\")[\"Delay Est/Arrival Duration\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique_shipment[df_unique_shipment[\"Delay Est/Arrival Duration\"] < pd.Timedelta(\"0 days\")].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique_shipment.fillna({\"Origin Ctry\":\"-\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ship_data[df_ship_data.duplicated(subset=[\"Shipment id\"])][\"Shipment id\"].value_counts().nlargest(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ship_data[df_ship_data[\"Shipment id\"] == 39640134][~ df_ship_data[df_ship_data[\"Shipment id\"] == 39640134].duplicated()].to_excel(\"duplicate.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams['figure.figsize'] = [15, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_unique_shipment[\"Route\"].value_counts().iplot(kind='bar')\n",
    "#df_unique_shipment[\"Route\"].value_counts().nlargest(50).plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = px.histogram(df_unique_shipment[\"Route\"]).update_xaxes(categoryorder=\"total descending\")\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Want to get a list of unique shipment\n",
    "#unique_shipment_ID = df_ship_data[\"Shipment id\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Want to get the columns that are at least 70% Filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_col_names(df, col_filled=70):\n",
    "\n",
    "    # Want to get the column with the most missing data\n",
    "    missing_value_series = df.isnull().sum() / df.shape[0] * 100.00\n",
    "    # Sort the missing %\n",
    "    missing_value_series.sort_values(ascending=False, inplace=True)\n",
    "    #missing_value_series\n",
    "    col_dict=missing_value_series.to_dict()\n",
    "    for k, d in col_dict.items():\n",
    "        print(\"{} : {}\".format(k,d))\n",
    "    \n",
    "    col = [k for k, d in col_dict.items() if d < (100 - col_filled)]\n",
    "    return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique_shipment[\"Route\"] = df_unique_shipment[\"Route\"].astype(\"str\")\n",
    "df_ship_routes['Route']  = df_ship_routes['Route'].astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if the data is of string type\n",
    "#type(df_unique_shipment['Route'])\n",
    "# type(df_ship_routes['Route'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = df_unique_shipment.merge(df_ship_routes, on=\"Route\", how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined=df_combined[df_combined[\"Region\"]==\"AP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined=df_combined[df_combined[\"Mode\"]!=\"Ferry\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_save = get_col_names(df_combined)\n",
    "col_to_save = [c for c in col_to_save if c.find(\"RouteCode Cleanup\") == -1]\n",
    "col_to_save = [c for c in col_to_save if c.find(\"Local Time\") == -1]\n",
    "print(\"\\n\\n\")\n",
    "for c in col_to_save:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Port of Discharge is 75% empty. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df_combined['Port of Discharge'].isna())/len(df_combined['Port of Discharge']) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only want columns that are more than 80% filled. \n",
    "df_combined = df_combined[col_to_save]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_col_names(df_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df_combined[\"Destination Ctry\"], title='Histogram of Destination Ctry').update_xaxes(categoryorder=\"total descending\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df_combined[\"Origin Ctry\"], title='Histogram of Origin Ctry').update_xaxes(categoryorder=\"total descending\", title=\"Origin Country\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined[df_combined[\"Description\"].isnull()][\"Route\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined[[\"Delay Est/Arrival Duration\", \"Arrived at Destination Port Milestone Time\", \"Est. Arrival at Destination Port Milestone Time\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_combined.iloc[5][[\"Delay Est/Arrival Duration\", \"Arrived at Destination Port Milestone Time\", \"Est. Arrival at Destination Port Milestone Time\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined[\"Delay Est/Arrival Duration (Hour)\"] = df_combined[\"Delay Est/Arrival Duration\"].apply(lambda x: x.total_seconds()/(60*60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined[\"Delay Est/Arrival Duration (Hour)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df_combined[df_combined[\"Origin Ctry\"].notnull()][[\"Delay Est/Arrival Duration (Hour)\", \"Origin Ctry\"]], title='Delay between estimates', color=\"Origin Ctry\").update_xaxes(categoryorder=\"total descending\", title=\"Time (Hours)\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"D:\\Google Drive\\Masters\\Sem 3\\Python_Stuff\\Aaron [No Ship]\")\n",
    "df_combined.to_csv(\"Cleaned_Data_{}.csv\".format(datetime.datetime.now().strftime(\"%Y%m%d\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Port of LoadingDestination CtryMode\" in df_combined.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.datetime.now().strftime(\"%Y%m%d\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
